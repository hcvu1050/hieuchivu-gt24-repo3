{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Check features after reducing cardinality\n",
    "(the tables used in this notebook are created by `scripts/model1_preprocess_3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "techniques_df = pd.read_pickle ('../data/processed/model1/processed_technnique_features.pkl')\n",
    "groups_df = pd.read_pickle ('../data/processed/model1/processed_group_features.pkl')\n",
    "train_labels_df = pd.read_pickle ('../data/processed/model1/processed_train_labels.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_ID\n",
       "G0006    388\n",
       "G0117    388\n",
       "G0047    388\n",
       "G0125    388\n",
       "G1001    388\n",
       "        ... \n",
       "G0036      2\n",
       "G0063      1\n",
       "G0002      1\n",
       "G0023      1\n",
       "G0029      1\n",
       "Name: count, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups  = train_labels_df[train_labels_df['label']==1]['group_ID'].value_counts()\n",
    "'G0054' in groups.index\n",
    "train_labels_df['group_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'s0105' in techniques_df['input_technique_software_id'].explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['technique_ID', 'input_technique_data_sources',\n",
       "       'input_technique_detection_name', 'input_technique_mitigation_id',\n",
       "       'input_technique_platforms', 'input_technique_software_id',\n",
       "       'input_technique_tactics', 'input_technique_description',\n",
       "       'input_technique_interaction_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_org_df['input_technique_software_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "def get_feature_length_stats(df: pd.DataFrame()):\n",
    "    for col in list (df.columns)[1:]:\n",
    "        if not isinstance(df[col].iloc[0], list): print ('{col}: scalar'.format (col = col))\n",
    "        else:\n",
    "                list_lengths = df[col].apply(lambda x: len(x))\n",
    "                avg_len = list_lengths.mean()\n",
    "                mode_len = mode(list_lengths)\n",
    "                max_len = list_lengths.max()\n",
    "                print ('{col} \\tmean_len: {mean_len}\\tmode_len: {mode_len}\\tmax_len: {max_len}'.format(col = col, mean_len= avg_len, mode_len = mode_len, max_len = max_len))\n",
    "        \n",
    "def get_vocab_size (df: pd.DataFrame):\n",
    "    for feature_name in df.columns[1:]:\n",
    "        if feature_name in ['input_group_description', 'input_technique_description', 'input_group_interaction_rate', 'input_technique_interaction_rate']: continue\n",
    "        vocab_size = len(df[feature_name].explode().unique())\n",
    "        print ('{feature_name}: vocab size = {vocab_size}'.format (feature_name = feature_name, vocab_size = vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "input_technique_data_sources \tmean_len: 3.154859967051071\tmode_len: 3\tmax_len: 14\n",
      "input_technique_detection_name \tmean_len: 3.154859967051071\tmode_len: 3\tmax_len: 14\n",
      "input_technique_mitigation_id \tmean_len: 2.1301482701812193\tmode_len: 1\tmax_len: 11\n",
      "input_technique_platforms \tmean_len: 2.510708401976936\tmode_len: 1\tmax_len: 10\n",
      "input_technique_software_id \tmean_len: 14.179571663920923\tmode_len: 1\tmax_len: 334\n",
      "input_technique_tactics \tmean_len: 1.2932454695222406\tmode_len: 1\tmax_len: 4\n",
      "input_technique_description: scalar\n",
      "input_group_software_id \tmean_len: 6.1911764705882355\tmode_len: 1\tmax_len: 46\n",
      "input_group_description: scalar\n",
      "AFTER\n",
      "input_technique_data_sources \tmean_len: 2.7528830313014825\tmode_len: 1\tmax_len: 9\n",
      "input_technique_detection_name \tmean_len: 2.7528830313014825\tmode_len: 1\tmax_len: 9\n",
      "input_technique_mitigation_id \tmean_len: 1.9588138385502472\tmode_len: 1\tmax_len: 8\n",
      "input_technique_platforms \tmean_len: 2.510708401976936\tmode_len: 1\tmax_len: 10\n",
      "input_technique_software_id \tmean_len: 10.72487644151565\tmode_len: 1\tmax_len: 196\n",
      "input_technique_tactics \tmean_len: 1.2932454695222406\tmode_len: 1\tmax_len: 4\n",
      "input_technique_description: scalar\n",
      "input_technique_interaction_rate: scalar\n",
      "input_group_software_id \tmean_len: 4.948529411764706\tmode_len: 1\tmax_len: 46\n",
      "input_group_description: scalar\n",
      "input_group_interaction_rate: scalar\n",
      "input_group_tactics \tmean_len: 24.904411764705884\tmode_len: 1\tmax_len: 108\n"
     ]
    }
   ],
   "source": [
    "print (\"BEFORE\")\n",
    "get_feature_length_stats (techniques_org_df)\n",
    "get_feature_length_stats (groups_org_df)\n",
    "print (\"AFTER\")\n",
    "get_feature_length_stats (techniques_df)\n",
    "get_feature_length_stats (groups_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "input_group_software_id: vocab size = 464\n",
      "input_technique_data_sources: vocab size = 106\n",
      "input_technique_detection_name: vocab size = 106\n",
      "input_technique_mitigation_id: vocab size = 44\n",
      "input_technique_platforms: vocab size = 11\n",
      "input_technique_software_id: vocab size = 636\n",
      "input_technique_tactics: vocab size = 14\n",
      "AFTER\n",
      "input_group_software_id: vocab size = 224\n",
      "input_group_tactics: vocab size = 15\n",
      "input_technique_data_sources: vocab size = 15\n",
      "input_technique_detection_name: vocab size = 15\n",
      "input_technique_mitigation_id: vocab size = 17\n",
      "input_technique_platforms: vocab size = 11\n",
      "input_technique_software_id: vocab size = 272\n",
      "input_technique_tactics: vocab size = 14\n"
     ]
    }
   ],
   "source": [
    "print (\"BEFORE\")\n",
    "get_vocab_size (groups_org_df)\n",
    "get_vocab_size (techniques_org_df)\n",
    "print (\"AFTER\")\n",
    "get_vocab_size (groups_df)\n",
    "get_vocab_size (techniques_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "input_technique_software_id\n",
      "         201\n",
      "s0363     72\n",
      "s0260     72\n",
      "s0154     72\n",
      "s0650     71\n",
      "        ... \n",
      "s0112      1\n",
      "s0001      1\n",
      "s0016      1\n",
      "s0014      1\n",
      "s0026      1\n",
      "Name: count, Length: 636, dtype: int64\n",
      "AFTER\n",
      "input_technique_software_id\n",
      "other    293\n",
      "         201\n",
      "s0154     72\n",
      "s0363     72\n",
      "s0260     72\n",
      "        ... \n",
      "s0249     14\n",
      "s0487     14\n",
      "s0136     14\n",
      "s0517     14\n",
      "s0579     14\n",
      "Name: count, Length: 272, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_name = 'input_technique_software_id'\n",
    "print ('BEFORE')\n",
    "print (techniques_org_df[feature_name].explode(feature_name).value_counts())\n",
    "print ('AFTER')\n",
    "print (techniques_df[feature_name].explode(feature_name).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- input_technique_data_sources\n",
      "input_technique_data_sources\n",
      "other                                                 312\n",
      "command_command_execution                             268\n",
      "process_process_creation                              226\n",
      "network_traffic_network_traffic_content               108\n",
      "file_file_modification                                104\n",
      "process_os_api_execution                               94\n",
      "file_file_creation                                     91\n",
      "network_traffic_network_traffic_flow                   86\n",
      "application_log_application_log_content                72\n",
      "windows_registry_windows_registry_key_modification     65\n",
      "network_traffic_network_connection_creation            61\n",
      "module_module_load                                     54\n",
      "file_file_access                                       47\n",
      "file_file_metadata                                     44\n",
      "                                                       39\n",
      "Name: count, dtype: int64\n",
      "-------- input_technique_detection_name\n",
      "input_technique_detection_name\n",
      "other                                312\n",
      "command_execution                    268\n",
      "process_creation                     226\n",
      "network_traffic_content              108\n",
      "file_modification                    104\n",
      "os_api_execution                      94\n",
      "file_creation                         91\n",
      "network_traffic_flow                  86\n",
      "application_log_content               72\n",
      "windows_registry_key_modification     65\n",
      "network_connection_creation           61\n",
      "module_load                           54\n",
      "file_access                           47\n",
      "file_metadata                         44\n",
      "                                      39\n",
      "Name: count, dtype: int64\n",
      "-------- input_technique_mitigation_id\n",
      "input_technique_mitigation_id\n",
      "other    220\n",
      "m1026    105\n",
      "          93\n",
      "m1018     89\n",
      "m1056     82\n",
      "m1047     78\n",
      "m1038     66\n",
      "m1042     59\n",
      "m1022     56\n",
      "m1031     55\n",
      "m1040     46\n",
      "m1027     44\n",
      "m1017     41\n",
      "m1032     41\n",
      "m1037     40\n",
      "m1028     39\n",
      "m1030     35\n",
      "Name: count, dtype: int64\n",
      "-------- input_technique_platforms\n",
      "input_technique_platforms\n",
      "windows             421\n",
      "macos               303\n",
      "linux               295\n",
      "pre                  88\n",
      "iaas                 84\n",
      "office_365           72\n",
      "network              65\n",
      "saas                 58\n",
      "google_workspace     56\n",
      "azure_ad             46\n",
      "containers           36\n",
      "Name: count, dtype: int64\n",
      "-------- input_technique_software_id\n",
      "input_technique_software_id\n",
      "other    293\n",
      "         201\n",
      "s0154     72\n",
      "s0363     72\n",
      "s0260     72\n",
      "        ... \n",
      "s0249     14\n",
      "s0487     14\n",
      "s0136     14\n",
      "s0517     14\n",
      "s0579     14\n",
      "Name: count, Length: 272, dtype: int64\n",
      "-------- input_technique_tactics\n",
      "input_technique_tactics\n",
      "defense_evasion         184\n",
      "persistence             113\n",
      "privilege_escalation     96\n",
      "credential_access        63\n",
      "resource_development     45\n",
      "discovery                44\n",
      "reconnaissance           43\n",
      "command_and_control      39\n",
      "collection               37\n",
      "execution                36\n",
      "impact                   26\n",
      "lateral_movement         22\n",
      "initial_access           19\n",
      "exfiltration             18\n",
      "Name: count, dtype: int64\n",
      "-------- input_technique_description\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_technique_description\n",
      " 0.175284    3\n",
      " 0.362935    3\n",
      "-0.262985    3\n",
      "-0.518338    3\n",
      "-0.676892    3\n",
      "            ..\n",
      "-0.077117    1\n",
      " 0.021594    1\n",
      "-0.342149    1\n",
      " 0.076021    1\n",
      " 1.116899    1\n",
      "Name: count, Length: 464544, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in techniques_df.columns[1:-1]:\n",
    "    print ('--------',col)\n",
    "    feature_name = col\n",
    "    print (techniques_df.explode(feature_name)[feature_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_pickle ('../data/processed/model1/processed_train_labels.pkl')\n",
    "cv_labels = pd.read_pickle ('../data/processed/model1/processed_cv_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T1001.002' 'T1021.007' 'T1027.006' 'T1029' 'T1036.007' 'T1052.001'\n",
      " 'T1053' 'T1055.004' 'T1056.004' 'T1074' 'T1087.004' 'T1090.004'\n",
      " 'T1098.005' 'T1137.006' 'T1187' 'T1222.001' 'T1491.002' 'T1499'\n",
      " 'T1546.013' 'T1547.004' 'T1547.012' 'T1553' 'T1556.007' 'T1558.001'\n",
      " 'T1563.002' 'T1566' 'T1584.003' 'T1584.005' 'T1584.006' 'T1586.003'\n",
      " 'T1588.006' 'T1590.001' 'T1593' 'T1608' 'T1614.001' 'T1615' 'T1649'\n",
      " 'T1651']\n"
     ]
    }
   ],
   "source": [
    "train_techniques =  (train_labels[train_labels['label'] == 1]['technique_ID'].unique())\n",
    "cv_techniques =  (cv_labels[cv_labels['label']==1]['technique_ID'].unique())\n",
    "unused_train_techniques = np.setdiff1d (cv_techniques, train_techniques)\n",
    "print (unused_train_techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some of the Techniques are only used in one of the Train or CV set but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (train_labels[train_labels['label'] == 1]['technique_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_org_df.columns == labels_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b- Check resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/model1/train_y_split.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vuchi\\GT24\\hieuchivu-gt24-repo3\\notebooks\\unit_test_6_m1_pp_script.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vuchi/GT24/hieuchivu-gt24-repo3/notebooks/unit_test_6_m1_pp_script.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_y_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv (\u001b[39m'\u001b[39m\u001b[39m../data/processed/model1/train_y_split.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vuchi/GT24/hieuchivu-gt24-repo3/notebooks/unit_test_6_m1_pp_script.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# train_cv_y_df = pd.read_csv ('../data/processed/model1/train_cv_y_split.csv')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vuchi/GT24/hieuchivu-gt24-repo3/notebooks/unit_test_6_m1_pp_script.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cv_y_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv (\u001b[39m'\u001b[39m\u001b[39m../data/processed/model1/cv_y_split.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hcv-gt24-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hcv-gt24-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hcv-gt24-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hcv-gt24-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hcv-gt24-env\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/model1/train_y_split.csv'"
     ]
    }
   ],
   "source": [
    "train_y_df = pd.read_csv ('../data/processed/model1/train_y_split.csv')\n",
    "# train_cv_y_df = pd.read_csv ('../data/processed/model1/train_cv_y_split.csv')\n",
    "cv_y_df = pd.read_csv ('../data/processed/model1/cv_y_split.csv')\n",
    "# test_y_df = pd.read_csv ('../data/processed/model1/test_y_split.csv')\n",
    "train_y_resampled_df = pd.read_csv ('../data/processed/model1/train_y_resampled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 3) no. of groups: 54\n",
      "label\n",
      "0.0    18473\n",
      "1.0     2007\n",
      "Name: count, dtype: int64\n",
      "(16007, 3) no. of groups: 54\n",
      "label\n",
      "0.0    12313\n",
      "1.0     3694\n",
      "Name: count, dtype: int64\n",
      "(5204, 3) no. of groups: 14\n",
      "label\n",
      "0.0    4640\n",
      "1.0     564\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in [train_y_df, train_y_resampled_df,cv_y_df]:\n",
    "    print (df.shape, 'no. of groups: {n}'.format(n =  df['group_ID'].nunique()))\n",
    "    print (df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Check exported dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.load ('../data/processed/model1/train_dataset/')\n",
    "cv_dataset = tf.data.Dataset.load ('../data/processed/model1/cv_dataset/')\n",
    "# test_dataset = tf.data.Dataset.load ('../data/processed/model1/test_dataset/')\n",
    "inputs = cv_dataset.element_spec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_technique_interaction_rate': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       " 'input_technique_software_id': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_technique_platforms': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_group_tactics': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_technique_description': TensorSpec(shape=(768,), dtype=tf.float32, name=None),\n",
       " 'input_technique_data_sources': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_group_interaction_rate': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       " 'input_technique_tactics': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_group_software_id': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_group_description': TensorSpec(shape=(768,), dtype=tf.float32, name=None),\n",
       " 'input_technique_mitigation_id': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64),\n",
       " 'input_technique_detection_name': RaggedTensorSpec(TensorShape([None]), tf.string, 0, tf.int64)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataset.element_spec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_technique_interaction_rate',\n",
       " 'input_technique_software_id',\n",
       " 'input_technique_platforms',\n",
       " 'input_technique_description',\n",
       " 'input_technique_data_sources',\n",
       " 'input_technique_tactics',\n",
       " 'input_technique_mitigation_id',\n",
       " 'input_technique_detection_name']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_technique = [item for item in list(inputs.keys()) if item.startswith ('input_technique')]\n",
    "input_technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_group_tactics',\n",
       " 'input_group_interaction_rate',\n",
       " 'input_group_software_id',\n",
       " 'input_group_description']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_group = [item for item in list(inputs.keys()) if item.startswith ('input_group')]\n",
    "input_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# count_zeros = 0\n",
    "# count_ones = 0\n",
    "# for features, labels in train_dataset:\n",
    "#     # 'labels' will be the second element in each tuple\n",
    "#     labels_array = labels.numpy()  # Convert labels tensor to numpy array\n",
    "    \n",
    "#     # Count occurrences of 0 and 1 in the labels\n",
    "#     count_zeros += (labels_array == 0).sum()\n",
    "#     count_ones += (labels_array == 1).sum()\n",
    "\n",
    "# # Print the counts\n",
    "# print(f\"Number of zeros: {count_zeros}\")\n",
    "# print(f\"Number of ones: {count_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_zeros = 0\n",
    "# count_ones = 0\n",
    "# for features, labels in cv_dataset:\n",
    "#     # 'labels' will be the second element in each tuple\n",
    "#     labels_array = labels.numpy()  # Convert labels tensor to numpy array\n",
    "    \n",
    "#     # Count occurrences of 0 and 1 in the labels\n",
    "#     count_zeros += (labels_array == 0).sum()\n",
    "#     count_ones += (labels_array == 1).sum()\n",
    "\n",
    "# # Print the counts\n",
    "# print(f\"Number of zeros: {count_zeros}\")\n",
    "# print(f\"Number of ones: {count_ones}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcv-gt24-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
